{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import dotenv\n",
    "import os\n",
    "import datetime\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm\n",
    "import psycopg2\n",
    "import psycopg2.extensions\n",
    "from psycopg2 import sql\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definições para requisição http\n",
    "\n",
    "Definição das variáveis para requisição http à api do github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")  # Substitua pelo seu token\n",
    "REPO_OWNER = \"CSSEGISandData\"\n",
    "REPO_NAME = \"COVID-19\"\n",
    "API_URL = f\"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/\"\n",
    "GITHUB_API_GRAPHQL_URL = \"https://api.github.com/graphql\"\n",
    "\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"token {GITHUB_TOKEN}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando Limites de Requisição\n",
    "\n",
    "Abaixo, bloco para testar quantas requisições faltam e quanto tempo falta para zerar o limite de requisições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limite de requisições por hora: 5000\n",
      "Requisições restantes: 5000\n",
      "Limite será zerado em: 2025-02-24 21:48:52\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://api.github.com/rate_limit\", headers=HEADERS)\n",
    "\n",
    "# Verifica o status da resposta\n",
    "if response.status_code == 200:\n",
    "    rate_limit = response.json()\n",
    "    core = rate_limit['rate']\n",
    "    limit = core['limit']\n",
    "    remaining = core['remaining']\n",
    "    reset_timestamp = core['reset']\n",
    "    reset_time = datetime.datetime.fromtimestamp(reset_timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    print(f\"Limite de requisições por hora: {limit}\")\n",
    "    print(f\"Requisições restantes: {remaining}\")\n",
    "    print(f\"Limite será zerado em: {reset_time}\")\n",
    "else:\n",
    "    print(f\"Erro ao verificar rate limit: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limite de requisições por hora: 5000\n",
      "Requisições restantes: 4996\n",
      "Limite será zerado em: 2025-02-25 01:31:54\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "{\n",
    "  rateLimit {\n",
    "    limit\n",
    "    remaining\n",
    "    resetAt\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "response = requests.post(GITHUB_API_GRAPHQL_URL, json={'query': query}, headers=HEADERS)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    rate_limit = response.json()['data']['rateLimit']\n",
    "    limit = rate_limit['limit']\n",
    "    remaining = rate_limit['remaining']\n",
    "    reset_timestamp = rate_limit['resetAt']\n",
    "    reset_time = datetime.datetime.strptime(reset_timestamp, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "    print(f\"Limite de requisições por hora: {limit}\")\n",
    "    print(f\"Requisições restantes: {remaining}\")\n",
    "    print(f\"Limite será zerado em: {reset_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "else:\n",
    "    print(f\"Erro ao verificar rate limit: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listagem dos arquivos presentes no repositório\n",
    "\n",
    "Bloco para listar todos os arquivos .csv presentes no repositório, da raiz às subpastas.\n",
    "\n",
    "Foi utilizada a api graphql para conseguir obter a lista de arquivos com menos requisições, assim, economizando o limite de requisições por hora da api do github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos CSV encontrados:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "caminho_completo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "nome_arquivo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "url_download",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7865cfb9-4f27-4e1a-aef6-83679a4c128b",
       "rows": [
        [
         "0",
         "csse_covid_19_data",
         "UID_ISO_FIPS_LookUp_Table.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv"
        ],
        [
         "1",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-01-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-01-2021.csv"
        ],
        [
         "2",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-01-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-01-2022.csv"
        ],
        [
         "3",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-01-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-01-2023.csv"
        ],
        [
         "4",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-02-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-02-2021.csv"
        ],
        [
         "5",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-02-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-02-2022.csv"
        ],
        [
         "6",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-02-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-02-2023.csv"
        ],
        [
         "7",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-03-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-03-2021.csv"
        ],
        [
         "8",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-03-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-03-2022.csv"
        ],
        [
         "9",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-03-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-03-2023.csv"
        ],
        [
         "10",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-04-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-04-2021.csv"
        ],
        [
         "11",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-04-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-04-2022.csv"
        ],
        [
         "12",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-04-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-04-2023.csv"
        ],
        [
         "13",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-05-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-05-2021.csv"
        ],
        [
         "14",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-05-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-05-2022.csv"
        ],
        [
         "15",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-05-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-05-2023.csv"
        ],
        [
         "16",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-06-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-06-2021.csv"
        ],
        [
         "17",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-06-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-06-2022.csv"
        ],
        [
         "18",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-06-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-06-2023.csv"
        ],
        [
         "19",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-07-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-07-2021.csv"
        ],
        [
         "20",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-07-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-07-2022.csv"
        ],
        [
         "21",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-07-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-07-2023.csv"
        ],
        [
         "22",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-08-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-08-2021.csv"
        ],
        [
         "23",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-08-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-08-2022.csv"
        ],
        [
         "24",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-08-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-08-2023.csv"
        ],
        [
         "25",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-09-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-09-2021.csv"
        ],
        [
         "26",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-09-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-09-2022.csv"
        ],
        [
         "27",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-09-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-09-2023.csv"
        ],
        [
         "28",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-10-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-10-2021.csv"
        ],
        [
         "29",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-10-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-10-2022.csv"
        ],
        [
         "30",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-10-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-10-2023.csv"
        ],
        [
         "31",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-11-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-11-2021.csv"
        ],
        [
         "32",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-11-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-11-2022.csv"
        ],
        [
         "33",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-11-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-11-2023.csv"
        ],
        [
         "34",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-12-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-12-2021.csv"
        ],
        [
         "35",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-12-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-12-2022.csv"
        ],
        [
         "36",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-12-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-12-2023.csv"
        ],
        [
         "37",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-13-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-13-2021.csv"
        ],
        [
         "38",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-13-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-13-2022.csv"
        ],
        [
         "39",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-13-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-13-2023.csv"
        ],
        [
         "40",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-14-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-14-2021.csv"
        ],
        [
         "41",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-14-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-14-2022.csv"
        ],
        [
         "42",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-14-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-14-2023.csv"
        ],
        [
         "43",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-15-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-15-2021.csv"
        ],
        [
         "44",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-15-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-15-2022.csv"
        ],
        [
         "45",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-15-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-15-2023.csv"
        ],
        [
         "46",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-16-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-16-2021.csv"
        ],
        [
         "47",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-16-2022.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-16-2022.csv"
        ],
        [
         "48",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-16-2023.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-16-2023.csv"
        ],
        [
         "49",
         "csse_covid_19_data/csse_covid_19_daily_reports",
         "01-17-2021.csv",
         "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-17-2021.csv"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2212
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caminho_completo</th>\n",
       "      <th>nome_arquivo</th>\n",
       "      <th>url_download</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>csse_covid_19_data</td>\n",
       "      <td>UID_ISO_FIPS_LookUp_Table.csv</td>\n",
       "      <td>https://raw.githubusercontent.com/CSSEGISandDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>csse_covid_19_data/csse_covid_19_daily_reports</td>\n",
       "      <td>01-01-2021.csv</td>\n",
       "      <td>https://raw.githubusercontent.com/CSSEGISandDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>csse_covid_19_data/csse_covid_19_daily_reports</td>\n",
       "      <td>01-01-2022.csv</td>\n",
       "      <td>https://raw.githubusercontent.com/CSSEGISandDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>csse_covid_19_data/csse_covid_19_daily_reports</td>\n",
       "      <td>01-01-2023.csv</td>\n",
       "      <td>https://raw.githubusercontent.com/CSSEGISandDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>csse_covid_19_data/csse_covid_19_daily_reports</td>\n",
       "      <td>01-02-2021.csv</td>\n",
       "      <td>https://raw.githubusercontent.com/CSSEGISandDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>csse_covid_19_data/csse_covid_19_time_series</td>\n",
       "      <td>time_series_covid19_confirmed_US.csv</td>\n",
       "      <td>https://raw.githubusercontent.com/CSSEGISandDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>csse_covid_19_data/csse_covid_19_time_series</td>\n",
       "      <td>time_series_covid19_confirmed_global.csv</td>\n",
       "      <td>https://raw.githubusercontent.com/CSSEGISandDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>csse_covid_19_data/csse_covid_19_time_series</td>\n",
       "      <td>time_series_covid19_deaths_US.csv</td>\n",
       "      <td>https://raw.githubusercontent.com/CSSEGISandDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>csse_covid_19_data/csse_covid_19_time_series</td>\n",
       "      <td>time_series_covid19_deaths_global.csv</td>\n",
       "      <td>https://raw.githubusercontent.com/CSSEGISandDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>csse_covid_19_data/csse_covid_19_time_series</td>\n",
       "      <td>time_series_covid19_recovered_global.csv</td>\n",
       "      <td>https://raw.githubusercontent.com/CSSEGISandDa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2212 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    caminho_completo  \\\n",
       "0                                 csse_covid_19_data   \n",
       "1     csse_covid_19_data/csse_covid_19_daily_reports   \n",
       "2     csse_covid_19_data/csse_covid_19_daily_reports   \n",
       "3     csse_covid_19_data/csse_covid_19_daily_reports   \n",
       "4     csse_covid_19_data/csse_covid_19_daily_reports   \n",
       "...                                              ...   \n",
       "2207    csse_covid_19_data/csse_covid_19_time_series   \n",
       "2208    csse_covid_19_data/csse_covid_19_time_series   \n",
       "2209    csse_covid_19_data/csse_covid_19_time_series   \n",
       "2210    csse_covid_19_data/csse_covid_19_time_series   \n",
       "2211    csse_covid_19_data/csse_covid_19_time_series   \n",
       "\n",
       "                                  nome_arquivo  \\\n",
       "0                UID_ISO_FIPS_LookUp_Table.csv   \n",
       "1                               01-01-2021.csv   \n",
       "2                               01-01-2022.csv   \n",
       "3                               01-01-2023.csv   \n",
       "4                               01-02-2021.csv   \n",
       "...                                        ...   \n",
       "2207      time_series_covid19_confirmed_US.csv   \n",
       "2208  time_series_covid19_confirmed_global.csv   \n",
       "2209         time_series_covid19_deaths_US.csv   \n",
       "2210     time_series_covid19_deaths_global.csv   \n",
       "2211  time_series_covid19_recovered_global.csv   \n",
       "\n",
       "                                           url_download  \n",
       "0     https://raw.githubusercontent.com/CSSEGISandDa...  \n",
       "1     https://raw.githubusercontent.com/CSSEGISandDa...  \n",
       "2     https://raw.githubusercontent.com/CSSEGISandDa...  \n",
       "3     https://raw.githubusercontent.com/CSSEGISandDa...  \n",
       "4     https://raw.githubusercontent.com/CSSEGISandDa...  \n",
       "...                                                 ...  \n",
       "2207  https://raw.githubusercontent.com/CSSEGISandDa...  \n",
       "2208  https://raw.githubusercontent.com/CSSEGISandDa...  \n",
       "2209  https://raw.githubusercontent.com/CSSEGISandDa...  \n",
       "2210  https://raw.githubusercontent.com/CSSEGISandDa...  \n",
       "2211  https://raw.githubusercontent.com/CSSEGISandDa...  \n",
       "\n",
       "[2212 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query GraphQL para listar arquivos e subpastas\n",
    "query = \"\"\"\n",
    "query ($caminho: String!) {\n",
    "  repository(owner: \"CSSEGISandData\", name: \"COVID-19\") {\n",
    "    object(expression: $caminho) {\n",
    "      ... on Tree {\n",
    "        entries {\n",
    "          name\n",
    "          type\n",
    "          oid\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Função recursiva para buscar arquivos CSV com caminho completo e URL de download\n",
    "def listar_arquivos_recursivo(caminho=\"master:csse_covid_19_data\"):\n",
    "    arquivos = []\n",
    "    variables = {\"caminho\": caminho}\n",
    "    response = requests.post(GITHUB_API_GRAPHQL_URL, json={'query': query, 'variables': variables}, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        dados = response.json()\n",
    "        if 'data' in dados and dados['data']['repository']['object']:\n",
    "            entradas = dados['data']['repository']['object']['entries']\n",
    "            \n",
    "            for item in entradas:\n",
    "                # Se for subpasta, chamar recursivamente\n",
    "                if item['type'] == 'tree':\n",
    "                    subcaminho = caminho + \"/\" + item['name']\n",
    "                    arquivos.extend(listar_arquivos_recursivo(subcaminho))  # Recurso recursivo\n",
    "                # Se for CSV, adicionar à lista\n",
    "                elif item['type'] == 'blob' and item['name'].endswith('.csv'):\n",
    "                    caminho_sem_arquivo = caminho.replace(\"master:\", \"\")\n",
    "                    url_download = f\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/{caminho_sem_arquivo}/{item['name']}\"\n",
    "                    arquivos.append({\n",
    "                        \"caminho_completo\": caminho_sem_arquivo,\n",
    "                        \"nome_arquivo\": item['name'],\n",
    "                        \"url_download\": url_download\n",
    "                    })\n",
    "        else:\n",
    "            print(\"Nenhum dado encontrado para o caminho:\", caminho)\n",
    "    else:\n",
    "        print(\"Erro na requisição:\", response.status_code, response.text)\n",
    "    \n",
    "    return arquivos\n",
    "\n",
    "# Executar a função e armazenar em DataFrame\n",
    "lista_csvs = listar_arquivos_recursivo()\n",
    "df_csvs = pd.DataFrame(lista_csvs)\n",
    "\n",
    "print(\"Arquivos CSV encontrados:\")\n",
    "display(df_csvs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para baixar um arquivo CSV mantendo a estrutura de diretórios\n",
    "async def baixar_arquivo(session, url_download, caminho_completo, nome_arquivo):\n",
    "    # Cria o caminho completo do diretório de destino\n",
    "    pasta_destino = os.path.join(\"files\", caminho_completo)\n",
    "    os.makedirs(pasta_destino, exist_ok=True)\n",
    "    caminho_arquivo = os.path.join(pasta_destino, nome_arquivo)\n",
    "    \n",
    "    # Se o arquivo já existe, pula o download\n",
    "    if os.path.exists(caminho_arquivo):\n",
    "        print(f\"{nome_arquivo} já existe, pulando download.\")\n",
    "        return\n",
    "\n",
    "    # Faz o download do arquivo\n",
    "    async with session.get(url_download) as response:\n",
    "        if response.status == 200:\n",
    "            conteudo = await response.read()\n",
    "            with open(caminho_arquivo, 'wb') as f:\n",
    "                f.write(conteudo)\n",
    "        else:\n",
    "            print(f\"Falha ao baixar {nome_arquivo}: {response.status}\")\n",
    "\n",
    "# Função principal para baixar todos os CSVs com estrutura de pastas\n",
    "async def baixar_csvs_assincrono(arquivos):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for arquivo in arquivos:\n",
    "            url_download = arquivo['url_download']\n",
    "            caminho_completo = arquivo['caminho_completo']\n",
    "            nome_arquivo = arquivo['nome_arquivo']\n",
    "            tasks.append(baixar_arquivo(session, url_download, caminho_completo, nome_arquivo))\n",
    "        \n",
    "        # Executa as tasks com tqdm para mostrar o progresso\n",
    "        for _ in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=\"Baixando arquivos\"):\n",
    "            await _\n",
    "            \n",
    "# Executar a função para baixar os CSVs\n",
    "await baixar_csvs_assincrono(df_csvs.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando arquivos CSV: 100%|██████████| 1143/1143 [00:38<00:00, 29.40arquivo/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos concatenados com sucesso, incluindo a coluna de data!\n"
     ]
    }
   ],
   "source": [
    "# Diretório onde os arquivos CSV estão localizados\n",
    "diretorio_csv = os.path.join(os.getcwd(),'files','csse_covid_19_data','csse_covid_19_daily_reports')\n",
    "\n",
    "def processar_csvs(diretorio_csv):\n",
    "    \"\"\"\n",
    "    Processa os arquivos CSV, adicionando a coluna 'date' e concatenando os dados.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    \n",
    "    # Usando tqdm para mostrar o progresso ao ler os arquivos CSV\n",
    "    for arquivo in tqdm(os.listdir(diretorio_csv), desc=\"Processando arquivos CSV\", unit=\"arquivo\"):\n",
    "        if arquivo.endswith('.csv'):\n",
    "            # Remover a extensão .csv e extrair a data\n",
    "            arquivo_sem_extensao = arquivo.replace('.csv', '')\n",
    "            data = arquivo_sem_extensao.split('-')\n",
    "            data = f\"{data[2]}-{data[0]}-{data[1]}\"  # Formata como 'yyyy-mm-dd'\n",
    "            \n",
    "            # Carregar o CSV em um DataFrame\n",
    "            df = pd.read_csv(os.path.join(diretorio_csv, arquivo))\n",
    "            \n",
    "            # Adicionar a coluna 'date'\n",
    "            df['date'] = data\n",
    "            \n",
    "            # Adicionar à lista\n",
    "            dfs.append(df)\n",
    "    \n",
    "    # Concatenar todos os DataFrames em um único\n",
    "    df_final = pd.concat(dfs, ignore_index=True)\n",
    "    return df_final\n",
    "\n",
    "df_final = processar_csvs(diretorio_csv)\n",
    "\n",
    "print(\"Arquivos concatenados com sucesso, incluindo a coluna de data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:\\git\\otg\\analista-bi\\files\\final\\daily_reports_concat.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Salvando CSV: 100%|██████████| 429/429 [01:27<00:00,  4.88linhas/s]\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(os.getcwd(),'files','final','daily_reports_concat.csv'))\n",
    "\n",
    "dir = os.path.join(os.getcwd(),'files','final')\n",
    "# Salvar o DataFrame final em um novo arquivo CSV\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "    \n",
    "caminho_csv_final = os.path.join(dir,'daily_reports_concat.csv')\n",
    "    \n",
    "# Abre o arquivo para escrita\n",
    "with open(caminho_csv_final, mode='w', newline='') as file:\n",
    "    # Escreve o cabeçalho uma única vez\n",
    "    df_final.head(0).to_csv(file, index=False)\n",
    "    \n",
    "    # Salva em chunks com barra de progresso\n",
    "    for i in tqdm(range(0, len(df_final), 10000), desc=\"Salvando CSV\", unit=\"linhas\"):\n",
    "        df_final.iloc[i:i+10000].to_csv(file, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FIPS', 'Admin2', 'Province_State', 'Country_Region', 'Last_Update',\n",
      "       'Lat', 'Long_', 'Confirmed', 'Deaths', 'Recovered', 'Active',\n",
      "       'Combined_Key', 'Incident_Rate', 'Case_Fatality_Ratio', 'date',\n",
      "       'Province/State', 'Country/Region', 'Last Update', 'Latitude',\n",
      "       'Longitude', 'Incidence_Rate', 'Case-Fatality_Ratio'],\n",
      "      dtype='object')\n",
      "   FIPS Admin2 Province_State Country_Region          Last_Update       Lat  \\\n",
      "0   NaN    NaN            NaN    Afghanistan  2021-01-02 05:22:33  33.93911   \n",
      "1   NaN    NaN            NaN        Albania  2021-01-02 05:22:33  41.15330   \n",
      "2   NaN    NaN            NaN        Algeria  2021-01-02 05:22:33  28.03390   \n",
      "3   NaN    NaN            NaN        Andorra  2021-01-02 05:22:33  42.50630   \n",
      "4   NaN    NaN            NaN         Angola  2021-01-02 05:22:33 -11.20270   \n",
      "\n",
      "       Long_  Confirmed  Deaths  Recovered  ...  Incident_Rate  \\\n",
      "0  67.709953    52513.0  2201.0    41727.0  ...     134.896578   \n",
      "1  20.168300    58316.0  1181.0    33634.0  ...    2026.409062   \n",
      "2   1.659600    99897.0  2762.0    67395.0  ...     227.809861   \n",
      "3   1.521800     8117.0    84.0     7463.0  ...   10505.403482   \n",
      "4  17.873900    17568.0   405.0    11146.0  ...      53.452981   \n",
      "\n",
      "  Case_Fatality_Ratio        date  Province/State Country/Region Last Update  \\\n",
      "0            4.191343  2021-01-01             NaN            NaN         NaN   \n",
      "1            2.025173  2021-01-01             NaN            NaN         NaN   \n",
      "2            2.764848  2021-01-01             NaN            NaN         NaN   \n",
      "3            1.034865  2021-01-01             NaN            NaN         NaN   \n",
      "4            2.305328  2021-01-01             NaN            NaN         NaN   \n",
      "\n",
      "  Latitude Longitude  Incidence_Rate  Case-Fatality_Ratio  \n",
      "0      NaN       NaN             NaN                  NaN  \n",
      "1      NaN       NaN             NaN                  NaN  \n",
      "2      NaN       NaN             NaN                  NaN  \n",
      "3      NaN       NaN             NaN                  NaN  \n",
      "4      NaN       NaN             NaN                  NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df_final.columns)\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_dados(df):\n",
    "    # Tratamento de NaN e NaT\n",
    "    for col in tqdm(df.columns, desc='Tratando dados'):\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].replace('NaT', np.nan)\n",
    "        elif df[col].dtype == 'datetime64[ns]':\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    # Convertendo colunas de data para o formato adequado\n",
    "    df['Last_Update'] = pd.to_datetime(df['Last_Update'], errors='coerce', format='%m/%d/%Y %H:%M')\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce', format='%Y-%m-%d')\n",
    "    df['Last Update'] = pd.to_datetime(df['Last Update'], errors='coerce', format='%m/%d/%Y %H:%M')\n",
    "    df = df.replace({np.nan: None})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inserir_dados(df, conn):\n",
    "    with conn.cursor() as cur:\n",
    "        # Criação da tabela caso ela não exista\n",
    "        cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS public.covid_data (\n",
    "            id serial4 NOT NULL PRIMARY KEY,\n",
    "            fips float8,\n",
    "            admin2 text,\n",
    "            province_state text,\n",
    "            country_region text,\n",
    "            last_update timestamp,\n",
    "            lat float8,\n",
    "            long_ float8,\n",
    "            confirmed float8,\n",
    "            deaths float8,\n",
    "            recovered float8,\n",
    "            active float8,\n",
    "            combined_key text,\n",
    "            incident_rate float8,\n",
    "            case_fatality_ratio float8,\n",
    "            \"date\" date,\n",
    "            \"Province/State\" text,\n",
    "            \"Country/Region\" text,\n",
    "            \"Last Update\" timestamp,\n",
    "            latitude float8,\n",
    "            longitude float8,\n",
    "            incidence_rate float8,\n",
    "            \"Case-Fatality_Ratio\" float8\n",
    "        );\n",
    "        \"\"\")\n",
    "        # Inserção dos dados com barra de progresso\n",
    "        for i, row in tqdm(df.iterrows(), total=df.shape[0], desc='Inserindo dados'):\n",
    "            cur.execute(sql.SQL(\"\"\"\n",
    "            INSERT INTO public.covid_data (\n",
    "                fips, admin2, province_state, country_region, last_update,\n",
    "                lat, long_, confirmed, deaths, recovered, active, combined_key,\n",
    "                incident_rate, case_fatality_ratio, \"date\", \"Province/State\",\n",
    "                \"Country/Region\", \"Last Update\", latitude, longitude,\n",
    "                incidence_rate, \"Case-Fatality_Ratio\"\n",
    "            ) VALUES (\n",
    "                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "                %s, %s, %s, %s, %s, %s\n",
    "            );\n",
    "            \"\"\"), tuple(row))\n",
    "        conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tratando dados: 100%|██████████| 22/22 [00:03<00:00,  7.24it/s]\n",
      "Inserindo dados: 100%|██████████| 4287473/4287473 [24:25<00:00, 2925.58it/s] \n"
     ]
    }
   ],
   "source": [
    "dotenv.load_dotenv()\n",
    "\n",
    "# Tratando os dados\n",
    "df_tratado = tratar_dados(df_final)\n",
    "\n",
    "# Conectando ao banco de dados\n",
    "conn = psycopg2.connect(\n",
    "    dbname=os.getenv('DB_NAME'), user=os.getenv('DB_USER'), password=os.getenv('DB_PASSWORD'), host=os.getenv('DB_HOST'), port=os.getenv('DB_PORT')\n",
    ")\n",
    "\n",
    "# Inserindo os dados\n",
    "inserir_dados(df_tratado, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
